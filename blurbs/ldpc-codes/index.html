<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LDPC codes vs RS codes | Giacomo's Blog</title><meta name=keywords content="hashes,concrete,theory"><meta name=description content="Some thoughts on LDPC codes vs RS codes"><meta name=author content="Giacomo Fenzi"><link rel=canonical href=https://wizardofmenlo.github.io/blurbs/ldpc-codes/><link crossorigin=anonymous href=/assets/css/stylesheet.5c3d2aa85a103c2d32fb4f6cbe26e29098f291f6fedf6b1d5b502c91573ae1ce.css integrity="sha256-XD0qqFoQPC0y+09svibikJjykfb+32sdW1AskVc64c4=" rel="preload stylesheet" as=style><link rel=icon href=https://wizardofmenlo.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wizardofmenlo.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wizardofmenlo.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wizardofmenlo.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="LDPC codes vs RS codes"><meta property="og:description" content="Some thoughts on LDPC codes vs RS codes"><meta property="og:type" content="article"><meta property="og:url" content="https://wizardofmenlo.github.io/blurbs/ldpc-codes/"><meta property="article:section" content="blurbs"><meta property="article:published_time" content="2024-10-14T00:00:00+00:00"><meta property="article:modified_time" content="2024-10-14T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="LDPC codes vs RS codes"><meta name=twitter:description content="Some thoughts on LDPC codes vs RS codes"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blurbs","item":"https://wizardofmenlo.github.io/blurbs/"},{"@type":"ListItem","position":2,"name":"LDPC codes vs RS codes","item":"https://wizardofmenlo.github.io/blurbs/ldpc-codes/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LDPC codes vs RS codes","name":"LDPC codes vs RS codes","description":"Some thoughts on LDPC codes vs RS codes","keywords":["hashes","concrete","theory"],"articleBody":"Just some spare thoughts on LDPC codes and RS codes (for IOPP based SNARKs), as an answer to Dev’s questions .\nTLDR; LDPC are an amazing avenue of research, that I hope to explore more, but I am bit skeptical on the current maturity of prover and verifier performance that they bring to the table.\nI think it makes sense to consider the question on two parts: prover time and verifier complexity. This might be a bit simplistic, and I am hoping to learn more about these codes (soon).\nProver time On the prover side, I like breaking down the complexity into two buckets: (i) arithmetic complexity and; (ii) hashing complexity. The first is time devoted to FFTs, encodings, anything that involves fops, while the latter is mostly dominated by the hashing to commit to oracles. Linear time encodable codes based SNARKs, such as Brakedown and Blaze, mainly improve on (i). Depending on how fast your hash is, I have seen this hashing cost to be the main chunk of the prover’s work (accounting for anything between 40%-60% in e.g. WHIR’s prover and the Polygon zkEVM). It is a very parallelizable chunk of work, but a large one at that. Typically, the size of (ii) is linear in the oracles being committed to i.e. $O(n/\\rho)$ (where $n$ is the instance size and $\\rho$ the rate of the code).\nLDPC codes improve (i), while either leaving (ii) unchanged or slightly worsening it (because the code have bad distance, typically a smaller rate is required, more on this on the verifier side).\nNow, how much can the improvement on (i) be? Asymptotically, moving from $O(n \\log n)$ to $O(n)$ can be a factor of 30x, which is very notable. However, the LDPC codes encoding is now competing against heavily optimized FFTs. Further, these FFTs are very parallel and running (typically) over small fields. And they are fast. While I think that the RAA codes encoding, when properly optimized, will leave FFTs behind, I can’t confidently say how much quicker we can feasibly get them. My gut feeling is that moving a RS based implementation to a small field is a much larger improvement gain (at a smaller engineering effort) than moving to a LDPC code.\nJust to give some datapoints on this, I was comparing the Blaze and Brakedown numbers with some of our measurements in WHIR. Take this comparison with a bunch of grains of salts: (i) the fields are different; (ii) the machines are different; (iii) we optimized our implementation a fair bit; and (iv) different number of cores (also unclear where the memory bandwidth bottleneck occur, so cannot just divide). WHIR on 2^28 variables (on 32 threads) produces a proof in 42s. Blaze (on 192 cores) takes 21s, and Brakedown (on 64 threads) takes similar time. So, the 28x theoretical speed-up only results in around a 2x concrete speed-up, at the moment. I am excited to see this reducing further, as I am sure it will, but that’s why I’m a bit lukewarm on it now.\nVerifier complexity Regarding verifier complexity, the term to really consider is (in the soundness error) $(1 - \\delta)^t \\leq 2^{-\\lambda}$, where $\\delta$ is the distance the system operates on and $t$ the number of queries to the initial oracle. WHIR and STIR basically show that this $t$ is the bottleneck on the verifier side, as with domain shifting the latter rounds are basically “free”. Note that $t$ is the bottleneck for both native verification and recursive verification. LDPC codes suffer from two factors: (i) not amazing initial distance to start with (ii) weak generic proximity gaps results (up to $\\delta_\\mathsf{C}/3$). This effectively limits how large of a distance $\\delta$ the prover can run at, making the verifier perform around 1000 queries1 (to this initial oracle). In comparison, for Reed-Solomon codes one can set $\\delta = 1 - \\sqrt{\\rho}$ or even $1- \\rho$ (depending on your religious belief) which can lead to as few as 50 or 25 queries to the initial oracle.\nSince the verifier needs to verify $t$ authentication paths (roughly $t \\cdot \\log n$) hashes, and this typically is its bottleneck (70% of the verifier runtime in WHIR), I don’t really expect that currently LDPC codes can give super competitive verifiers.\nImproving the distance of the LDPC code and getting stronger proximity gaps results would of course completely change this section, but if I said I understood what is going on in both these areas I would lie.\nThis is for RAA codes in the Blaze paper, Brakedown is around 3000. ↩︎\n","wordCount":"760","inLanguage":"en","datePublished":"2024-10-14T00:00:00Z","dateModified":"2024-10-14T00:00:00Z","author":{"@type":"Person","name":"Giacomo Fenzi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wizardofmenlo.github.io/blurbs/ldpc-codes/"},"publisher":{"@type":"Organization","name":"Giacomo's Blog","logo":{"@type":"ImageObject","url":"https://wizardofmenlo.github.io/favicon.ico"}}}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-183HXT3DZB"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-183HXT3DZB")</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css integrity=sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js integrity=sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\begin{equation}",right:"\\end{equation}",display:!0},{left:"\\begin{equation*}",right:"\\end{equation*}",display:!0},{left:"\\begin{align}",right:"\\end{align}",display:!0},{left:"\\begin{align*}",right:"\\end{align*}",display:!0},{left:"\\begin{alignat}",right:"\\end{alignat}",display:!0},{left:"\\begin{gather}",right:"\\end{gather}",display:!0},{left:"\\begin{CD}",right:"\\end{CD}",display:!0}],throwOnError:!1})})</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://wizardofmenlo.github.io/ accesskey=h title="Giacomo Fenzi"><img src=https://wizardofmenlo.github.io/favicon.ico alt aria-label=logo height=18 width=18>Giacomo Fenzi</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://wizardofmenlo.github.io/about title=About><span>About</span></a></li><li><a href=https://wizardofmenlo.github.io/papers/ title=Papers><span>Papers</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>LDPC codes vs RS codes</h1><div class=post-meta><span title='2024-10-14 00:00:00 +0000 UTC'>October 2024</span>&nbsp;&#183;&nbsp;Giacomo Fenzi&nbsp;&#183;&nbsp;<a href=https://eprint.iacr.org/2024/1586 rel="noopener noreferrer" target=_blank>ePrint: 2024/1586</a></div></header><div class=post-content><p>Just some spare thoughts on LDPC codes and RS codes (for IOPP based SNARKs), as an answer to <a href=https://x.com/valardragon/status/1845620037165425059 target=_blank>Dev&rsquo;s questions</a>
.</p><p><strong>TLDR; LDPC are an amazing avenue of research, that I hope to explore more, but I am bit skeptical on the current maturity of prover and verifier performance that they bring to the table.</strong></p><p>I think it makes sense to consider the question on two parts: prover time and verifier complexity. This might be a bit simplistic, and I am hoping to learn more about these codes (soon).</p><hr><h2 id=prover-time>Prover time</h2><p>On the prover side, I like breaking down the complexity into two buckets: (i) <strong>arithmetic complexity</strong> and; (ii) <strong>hashing complexity</strong>. The first is time devoted to FFTs, encodings, anything that involves fops, while the latter is mostly dominated by the hashing to commit to oracles.
Linear time encodable codes based SNARKs, such as Brakedown and Blaze, mainly improve on (i). Depending on how fast your hash is, I have seen this hashing cost to be the main chunk of the prover&rsquo;s work (accounting for anything between 40%-60% in e.g. WHIR&rsquo;s prover and the Polygon zkEVM). It is a very parallelizable chunk of work, but a large one at that.
Typically, the size of (ii) is linear in the oracles being committed to i.e. $O(n/\rho)$ (where $n$ is the instance size and $\rho$ the rate of the code).</p><p>LDPC codes improve (i), while either leaving (ii) unchanged or slightly worsening it (because the code have bad distance, typically a smaller rate is required, more on this on the verifier side).</p><p>Now, how much can the improvement on (i) be? Asymptotically, moving from $O(n \log n)$ to $O(n)$ can be a factor of 30x, which is very notable. However, the LDPC codes encoding is now competing against heavily optimized FFTs. Further, these FFTs are very parallel and running (typically) over small fields. And they are <strong>fast</strong>. While I think that the RAA codes encoding, when properly optimized, will leave FFTs behind, I can&rsquo;t confidently say how much quicker we can feasibly get them. My gut feeling is that moving a RS based implementation to a small field is a much larger improvement gain (at a smaller engineering effort) than moving to a LDPC code.</p><p>Just to give some datapoints on this, I was comparing the Blaze and Brakedown numbers with some of our measurements in WHIR. Take this comparison with a bunch of grains of salts: (i) the fields are different; (ii) the machines are different; (iii) we optimized our implementation a fair bit; and (iv) different number of cores (also unclear where the memory bandwidth bottleneck occur, so cannot just divide).
WHIR on 2^28 variables (on 32 threads) produces a proof in 42s. Blaze (on 192 cores) takes 21s, and Brakedown (on 64 threads) takes similar time.
So, the 28x theoretical speed-up only results in around a 2x concrete speed-up, at the moment. I am excited to see this reducing further, as I am sure it will, but that&rsquo;s why I&rsquo;m a bit lukewarm on it now.</p><h2 id=verifier-complexity>Verifier complexity</h2><p>Regarding verifier complexity, the term to really consider is (in the soundness error) $(1 - \delta)^t \leq 2^{-\lambda}$, where $\delta$ is the distance the system operates on and $t$ the number of queries to the initial oracle.
WHIR and STIR basically show that this $t$ is the bottleneck on the verifier side, as with domain shifting the latter rounds are basically &ldquo;free&rdquo;. Note that $t$ is the bottleneck for both <strong>native verification</strong> and <strong>recursive verification</strong>.
LDPC codes suffer from two factors: (i) not amazing initial distance to start with (ii) weak generic proximity gaps results (up to $\delta_\mathsf{C}/3$). This effectively limits how large of a distance $\delta$ the prover can run at, making the verifier perform around 1000 queries<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> (to this initial oracle).
In comparison, for Reed-Solomon codes one can set $\delta = 1 - \sqrt{\rho}$ or even $1- \rho$ (depending on your religious belief) which can lead to as few as 50 or 25 queries to the initial oracle.</p><p>Since the verifier needs to verify $t$ authentication paths (roughly $t \cdot \log n$) hashes, and this typically is its bottleneck (70% of the verifier runtime in WHIR), I don&rsquo;t really expect that currently LDPC codes can give super competitive verifiers.</p><p>Improving the distance of the LDPC code and getting stronger proximity gaps results would of course completely change this section, but if I said I understood what is going on in both these areas I would lie.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>This is for RAA codes in the Blaze paper, Brakedown is around 3000.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://wizardofmenlo.github.io/tags/hashes/>hashes</a></li><li><a href=https://wizardofmenlo.github.io/tags/concrete/>concrete</a></li><li><a href=https://wizardofmenlo.github.io/tags/theory/>theory</a></li></ul></footer></article></main><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>